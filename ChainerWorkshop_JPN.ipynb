{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習APIで学習機の実装を加速させる\n",
    "\n",
    "__目次__\n",
    "\n",
    "- <a href=\"#AD_bg\">自動微分について</a>\n",
    "  - <a href=\"#AD_bg_forwardone\">フォワードモード（1変数の例）</a>\n",
    "  - <a href=\"#AD_bg_forwardmulti\">フォワードモード（多変数の例）</a>\n",
    "  - <a href=\"#AD_bg_reverse\">リバースモード</a>\n",
    "- <a href=\"#NN_bg\">ニューラルネットワークと逆伝播法</a>\n",
    "- <a href=\"#chainer_bg\">Chainerを使ってみよう</a>\n",
    "  - <a href=\"#chainer_exSimple\">簡単な計算</a>\n",
    "  - <a href=\"#chainer_linreg\">線形回帰での最小二乗法を再現</a>\n",
    "  - <a href=\"#chainer_exNonLin\">任意の活性化関数を用いた非線形モデル</a>\n",
    "  - <a href=\"#chainer_lgstreg\">多クラスのロジスティック回帰の自作と比較</a>\n",
    "  - <a href=\"#chainer_newopt\">最適化と自分の手で</a>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"AD_bg\"></a>\n",
    "## 自動微分について\n",
    "\n",
    "一言でいうと、自動微分（automatic differentiation, AD）とは、連鎖律を巧妙に繰り返して使うことで、合成関数の微分計算を実装する多種の手法のことである。まず重要なことを述べておくと、\n",
    "\n",
    "- 数式処理も近似もせず、合成関数のパーツから解析的に求める。\n",
    "\n",
    "- 代表的なものとしてボトムアップ型もトップダウン型もあって、扱っている関数の入力と出力それぞれの数によって、どれが効率的かが違ってくる。\n",
    "\n",
    "さて、簡単な事例から見ていこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"AD_bg_forwardone\"></a>\n",
    "### フォワードモード（1変数の例）\n",
    "\n",
    "まずは一変数の関数からなる単純な合成関数を例として取り上げて、ボトムアップ型の方法を見ていくことにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "関数$f(g(h(x)))$を考える。\n",
    "\n",
    "これらの$f,g,h$が$\\mathbb{R}$の上で微分可能で、実数値を返す関数とする。\n",
    "\n",
    "やりたいこと：$x$について、$f(g(h(x)))$の微分を求めたい（導関数の取る値を計算したい）。\n",
    "\n",
    "次の表現を使うと便利である。\n",
    "\n",
    "\\begin{align*}\n",
    "u_{0} & = x\\\\\n",
    "u_{1} & = h(u_{0})\\\\\n",
    "u_{2} & = g(u_{1})\\\\\n",
    "u_{3} & = f(u_{2}).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "連鎖律を何度か使うと、以下のように展開できる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{d u_{3}}{d x} & = \\left(\\frac{d u_{3}}{d u_{2}}\\frac{d u_{2}}{d x}\\right)\\\\\n",
    "& = \\frac{d u_{3}}{d u_{2}}\\left(\\frac{d u_{2}}{d u_{1}}\\frac{d u_{1}}{d x}\\right)\\\\\n",
    "& = \\frac{d u_{3}}{d u_{2}}\\frac{d u_{2}}{d u_{1}} \\left(\\frac{d u_{1}}{d u_{0}}\\frac{d u_{0}}{d x}\\right).\n",
    "\\end{align*}\n",
    "\n",
    "括弧の中にあるところに注視しながら、「層」ごとに入力$x$についての微分を次のように定義する。\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{u}_{i} = \\frac{d u_{i}}{d x}, \\quad i = 0,1,\\ldots,3\n",
    "\\end{align*}\n",
    "\n",
    "明らかな通り、「下層」から始めると、次のように全層分を再帰的に計算できる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{u}_{i} = \\frac{d u_{i}}{d u_{i-1}} \\dot{u}_{i-1}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードモードの自動微分のアルゴリズムをざっくりまとめると次の通りである。\n",
    "\n",
    "0. シードたる$\\dot{u}_{0}$を計算しておく（普通は$\\dot{u}_{0}=1$）\n",
    "\n",
    "0. 以降、$i=1,2,\\ldots$に対して：\n",
    "   0. $d u_{i} / d u_{i-1}$を計算\n",
    "   0. $\\dot{u}_{i-1}$を用いて、$\\dot{u}_{i}$を計算\n",
    "\n",
    "上記の通りに、有限個の計算を経て、$d f(g(h(x))) / dx$を正しく計算することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"AD_bg_forwardmulti\"></a>\n",
    "### フォワードモード（多変数の例）\n",
    "\n",
    "次は多変数への拡張を考える。\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{x} \\in \\mathbb{R}^{d_{0}}, \\enspace h:\\mathbb{R}^{d_{0}} \\to \\mathbb{R}^{d_{1}}, \\enspace g:\\mathbb{R}^{d_{1}} \\to \\mathbb{R}^{d_{2}}, \\enspace f:\\mathbb{R}^{d_{2}} \\to \\mathbb{R}^{d_{3}}\\end{align*}\n",
    "\n",
    "先ほどと同様に、いくつかの層に分けて、その入出力をベクトル表記すると以下のようになる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{u}_{0} & = \\mathbf{x}\\\\\n",
    "\\mathbf{u}_{1} & = h(\\mathbf{u}_{0})\\\\\n",
    "\\mathbf{u}_{2} & = g(\\mathbf{u}_{1})\\\\\n",
    "\\mathbf{u}_{3} & = f(\\mathbf{u}_{2}).\n",
    "\\end{align*}\n",
    "\n",
    "流れは特に変わらないが、ここでは通常の微分ではなく、__偏微分__である。偏微分をたくさん整列させたヤコビ行列が基本となる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力を$\\mathbf{x} = (x_{1},\\ldots,x_{d_{0}})$、各層の出力を$\\mathbf{u}_{i}=(u_{i,1},\\ldots,u_{i,d_{i}})$と書く。次のように各層の出力を下層の入力について微分したヤコビ行列を表わす。\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{U}_{i} = \\left[ \\frac{\\partial u_{i,j}}{\\partial x_{k}} \\right]_{j,k},\n",
    "\\end{align*}\n",
    "\n",
    "この行列の形は$(d_{i} \\times d_{0})$である。\n",
    "\n",
    "前節の肝ともいえる再帰的な演算をここで多次元へと拡張する。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial u_{i,j}}{\\partial x_{k}} = \\sum_{l=1}^{d_{i-1}} \\frac{\\partial u_{i,j}}{\\partial u_{i-1,l}} \\frac{\\partial u_{i-1,l}}{\\partial x_{k}}\n",
    "\\end{align*}\n",
    "\n",
    "これは各$i=1,2\\ldots$と$j \\in [d_{i}]$に対して定義されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各層の入出力だけで出来上がる$(d_{i} \\times d_{i-1})$ヤコビ行列もある。\n",
    "\n",
    "\\begin{align*}\n",
    "J_{i} = \\left[\\frac{\\partial u_{i,j}}{\\partial u_{i-1,k}}\\right]_{j,k},\n",
    "\\end{align*}\n",
    "\n",
    "この2つをかけておくと、行列の掛け算による再帰的計算式が得られる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\dot{U}_{i} = J_{i}\\dot{U}_{i-1}.\n",
    "\\end{align*}\n",
    "\n",
    "今度はシードたるものが$\\dot{U}_{0}$で、普通は単位行列となるが、あとは先述の一変数のときとまったく同様に進む。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__練習問題__\n",
    "\n",
    "0. 以下の関数について「層」に分けて、計算の順序を明記すること。\n",
    "\n",
    "\\begin{align*}\n",
    "f(x_{1},x_{2}) & = x_{1}x_{2} + \\sin(x_{1})\\\\\n",
    "f(x_{1},x_{2}) & = x_{1}+x_{2} + 2\\exp(x_{1}x_{2})\\\\\n",
    "f(x_{1},x_{2}) & = \\frac{x_{1}^{3}}{x_{2}} + \\exp(\\sin(x_{1}))\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"AD_bg_reverse\"></a>\n",
    "### リバースモード\n",
    "\n",
    "正方向のほうは入力から計算していくため自然でわかりやすいが、入力変数が多い場合は計算が大変である。一方のリバースモードは少し変わった計算をするが、フォワードモードが遅いときには活躍することが多い。\n",
    "\n",
    "前の例をここでも使うことにする。$y = f(g(h(x)))$という合成関数であったことを思い出して、連鎖律を駆使すると以下のように展開できる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{d y}{d x} & = \\left(\\frac{d y}{d u_{0}} \\frac{d u_{0}}{d x}\\right)\\\\\n",
    "& = \\left(\\frac{d y}{d u_{1}} \\frac{d u_{1}}{d u_{0}}\\right) \\frac{d u_{0}}{d x}\\\\\n",
    "& = \\left(\\frac{d y}{d u_{2}} \\frac{d u_{2}}{d u_{1}}\\right) \\frac{d u_{1}}{d u_{0}} \\frac{d u_{0}}{d x}\\\\\n",
    "& = \\left(\\frac{d y}{d u_{3}} \\frac{d u_{3}}{d u_{2}}\\right) \\frac{d u_{2}}{d u_{1}} \\frac{d u_{1}}{d u_{0}} \\frac{d u_{0}}{d x}.\n",
    "\\end{align*}\n",
    "\n",
    "ここでもやはり括弧の中に注視しながら、今度は上層の出力を、任意の中間層の出力について微分を取ることが重要になる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{u}_{i} = \\frac{d y}{d u_{i}}, \\quad i=0,1,2,3.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の通り、この新しい微分を再帰的に求めることができる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{u}_{i} = \\bar{u}_{i+1} \\frac{d u_{i+1}}{d u_{i}}.\n",
    "\\end{align*}\n",
    "\n",
    "最上層のインデックスが$K$であるとすれば、リバースモードの自動微分は概ね次のように行われる。\n",
    "\n",
    "0. シードたる$\\bar{u}_{K}$を計算しておく（普通は$\\bar{u}_{K}=1$）\n",
    "0. 各$i=0,1,\\ldots,K-1$に対して：\n",
    "   0. $d u_{K-i} / d u_{K-i-1}$を計算\n",
    "   0. $\\bar{u}_{K-i}$を使って、$\\bar{u}_{K-i-1}$を計算\n",
    "\n",
    "正方向とはまさに逆で、上層から下りていくという流れである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多変数への拡張も想像できるように行なう。$\\mathbf{y} = \\mathbf{u}_{K}$とおくと、各層の出力で微分を求めると以下のようになる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial y_{j}}{\\partial u_{i,k}} = \\sum_{l=1}^{d_{i+1}} \\frac{\\partial y_{j}}{\\partial u_{i+1,l}} \\frac{\\partial u_{i+1,l}}{\\partial u_{i,k}}\n",
    "\\end{align*}\n",
    "\n",
    "これを各$i=0,1,\\ldots,K-1$と$k \\in [d_{i}]$に対して定義される。\n",
    "\n",
    "2種のヤコビ行列を以下のように表わす。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{U}_{i} & = \\left[ \\frac{\\partial y_{j}}{\\partial u_{i,k}} \\right]_{j,k} \\quad (d_{K} \\times d_{i}), \\quad i = 0,1,\\ldots,K \\\\\n",
    "\\widetilde{J}_{i} & = \\left[ \\frac{\\partial u_{i+1,j}}{\\partial u_{i,k}} \\right]_{j,k} \\quad (d_{i+1} \\times d_{i}), \\quad i=0,1,\\ldots,K-1.\n",
    "\\end{align*}\n",
    "\n",
    "シードが$\\bar{U}_{K}$で、普通は単位行列となるのだが、これさえあればあとは再帰的に「下りていく」だけである。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{U}_{i} = \\bar{U}_{i+1} \\widetilde{J}_{i}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械学習では、実数値を返すロス関数の勾配を求めること、つまり$d_{K}=1$となることが多い。\n",
    "\n",
    "<img src=\"img/mtx_mult_fromleft.png\"  alt=\"Matrix multiplication from left\" width=\"243\"  height=\"250\" />\n",
    "\n",
    "うまく実装すると、$d_{K} \\ll d_{0}$という状況下では、フォワードよりも、リバースのほうが格段に速い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"NN_bg\"></a>\n",
    "## ニューラルネットワークと逆伝播法\n",
    "\n",
    "ニューラルネットワークを定式化するにあたって、2つの関係式を用いることでほぼ何でも表せる。\n",
    "\n",
    "\\begin{align*}\n",
    "x_{j} & = \\sum_{i \\to j} w_{ij}y_{i}\\\\\n",
    "y_{j} & = f_{j}(x_{j})\n",
    "\\end{align*}\n",
    "\n",
    "この$j \\in \\mathcal{V}$がユニット（ノードなどとも）のインデックスである。\n",
    "\n",
    "- $x_{j}$は$j$番目のユニットへの入力。\n",
    "- $y_{j}$は$j$番目のユニットからの出力。\n",
    "- $f_{j}$は$j$番目のユニットの活性化関数。\n",
    "- \"$i \\to j$\"とは、$j$に接続する（直接$j$の入力に寄与する）すべてのユニット。\n",
    "\n",
    "「ユニット$i$がユニット$j$に接続する」ことを$e_{i,j}=1$で表し、そうでない場合は$e_{i,j}=0$とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの「層」はユニットの部分集合である。\n",
    "\n",
    "\\begin{align*}\n",
    "V_{1}, V_{2}, \\ldots, V_{L} \\subseteq \\mathcal{V}.\n",
    "\\end{align*}\n",
    "\n",
    "簡明でよく使われる構造としては、フィードフォワードが代表的である。我々の記号を使うと、任意の$i \\in V_{l}$, $j \\in V_{m}$について、\n",
    "\n",
    "\\begin{align*}\n",
    "m \\geq l \\implies e_{j,i} = 0\n",
    "\\end{align*}\n",
    "\n",
    "と下層から上層へと計算をきれいに分離できるモデルである。\n",
    "\n",
    "- 一般には何でも良いが、よくある「fully connected」層とは、各$i \\in V_{l}$と$j \\in V_{l+1}$に対して、$e_{i,j}=1$が成り立つということである。\n",
    "\n",
    "- $m > l+1$でも$e_{i,j}=1$となることもある（\"skip-layer\"接続）。\n",
    "\n",
    "- 任意の$i$に対して$e_{i,j}=0$であれば、$j$を__入力ユニット__と呼ぶ。\n",
    "\n",
    "- 任意の$i$に対して$e_{j,i}=0$であれば、$j$を__出力ユニット__と呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有名な活性化関数をいくつかピックアップ：\n",
    "\n",
    "- 線形：$f(x) = x$\n",
    "- 閾値：$f(x) = I\\{x > 0\\}$\n",
    "- ロジスティック：$f(x) = e^{x}/(1+e^{x})$\n",
    "- Rectified linear unit: $f(x) = \\max\\{0,x\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワークの重みが最適化の対象となることが多いが、そのためには何らかの目的関数が必要である。仮にそれを$L$と書く。出力層$O \\subset \\mathcal{V}$に直接的に依存することが多い。$\\ell_{2}$誤差（つまり$\\ell_{2}$ノルムの二乗をとったもの）が回帰問題では定番の一つである。\n",
    "\n",
    "\\begin{align*}\n",
    "L = \\sum_{l \\in O} (t_{l} - y_{l})^{2},\n",
    "\\end{align*}\n",
    "\n",
    "これらの$t_{l}$が出力層の各ユニットの値である。2018年現在、最適化法として、偏微分を求めて勾配ベクトルだけを使った反復的な更新が主流である。前の章でも扱っている最急降下法の一種である。\n",
    "\n",
    "\\begin{align*}\n",
    "w_{ij} \\gets w_{ij} - \\eta \\frac{\\partial L}{\\partial w_{ij}}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、ロス関数の返す値と、任意の重みパラメータ$w_{ij}$の依存関係についてもう少し詰めていくことにしよう。インデックス$j$に注目しつつ、以下の数量が重要である。\n",
    "\n",
    "\\begin{align*}\n",
    "L & = L((y_{l})_{l \\in O})\\\\\n",
    "y_{l} & = f_{l}(x_{l})\\\\\n",
    "x_{l} & = x_{l}(y_{j})\\\\\n",
    "y_{j} & = f_{j}(x_{j})\n",
    "\\end{align*}\n",
    "\n",
    "1行目：ロス関数$L$は出力層の関数であるとしている。2行目：出力層の出力値は言うまでもなくその層の入力に依存する。3行目：出力層の入力が$j$番目のユニットに依存するならば、$x_{l}$を$y_{j}$の関数と見るべきである。ここで「依存する」ことは直接的に接続しているときも、間接的に接続しているときもいえる。4行目：あとは$j$番目ユニットの出力がどのように$w_{ij}$に依存するかは、その入力値$x_{j}$と活性化関数$f_{j}$によって決まる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上のことを踏まえて、連鎖律を繰り返して適用することによって、便利な計算式を導出することができる。活性化関数はみな微分可能であるとして、以下のように展開できる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial w_{ij}} & = \\sum_{l \\in O} \\frac{\\partial L}{\\partial y_{l}} \\frac{\\partial y_{l}}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial x_{j}} \\frac{\\partial x_{j}}{\\partial w_{ij}}\\\\\n",
    "& = y_{i} f_{j}^{\\prime}(x_{j}) \\sum_{l \\in O} \\frac{\\partial L}{\\partial y_{l}} \\frac{\\partial y_{l}}{\\partial y_{j}}\\\\\n",
    "& = y_{i} f_{j}^{\\prime}(x_{j}) \\frac{\\partial L}{\\partial y_{j}}.\n",
    "\\end{align*}\n",
    "\n",
    "便宜上、ここで$\\delta_{j} = f_{j}^{\\prime}(x_{j}) (\\partial L / \\partial y_{j})$と定義しておくと、綺麗に書き換えられる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial w_{ij}} = y_{i} \\delta_{j}.\n",
    "\\end{align*}\n",
    "\n",
    "このデルタに注目して、効率的な計算方法を導き出したのが、\"generalized delta rule\"と呼ばれる著名な手法である。RumelhartとMcClellandの両氏率いる研究グループによって、80年代なかばに知名度が急上昇した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一つの良い計算方法は、最上層のユニットのデルタを計算し、それを下層へと「伝播」させる。これは実際のところ、難しいことではない。先述の通り、出力層の$l \\in O$では、$\\delta_{l}$はロス関数の定義からすぐに計算できる。たとえば、2乗誤差の場合、以下のような形を取る。\n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_{l} & = 2y_{l}(1 - y_{l})(y_{l} - t_{l}), & \\text{ logistic activations}\\\\\n",
    "\\delta_{l} & = 2(y_{l} - t_{l}), & \\text{ linear activations}\n",
    "\\end{align*}\n",
    "\n",
    "ほかのロス関数や活性化関数でもまったく同様に求めることができる。\n",
    "\n",
    "それから、出力層以外のユニット$l \\notin O$について重要なのは、$y_{l}$が直接接続しているユニットを追っていくことである。それ以外のユニットは$L$の値を考える上で関係がないので、無視しても良い。展開すると以下のようになる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial y_{l}} & = \\sum_{i:l \\to i} \\frac{\\partial L}{\\partial y_{i}} \\frac{\\partial y_{i}}{\\partial y_{l}}\\\\\n",
    "& = \\sum_{i:l \\to i} \\frac{\\partial L}{\\partial y_{i}} f_{i}^{\\prime}(x_{i}) w_{li}.\n",
    "\\end{align*}\n",
    "\n",
    "前の定義を利用して整理しておくと、任意のデルタの再帰的な表現が得られる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_{l} = f_{l}^{\\prime}(x_{l}) \\sum_{i:l \\to i} \\delta_{i} w_{li}.\n",
    "\\end{align*}\n",
    "\n",
    "数式では明確であるが、言葉でも難しいことはない。任意の$\\delta_{l}$について、もし$l \\to i$を満たすあらゆるユニット$i$の$\\delta_{i}$をすでに計算しているのであれば、その単純な線形和で$\\delta_{l}$を手に入れることができる。上から始まり、段々と下りていく。これは典型的な「逆伝播法(back-propagation)」である。\n",
    "\n",
    "用語について： 入力層から入って、各ユニットの$y_{j}$を求める一連の作業をフォワードパス(*forward pass*)と呼ぶことが多い。これに対して、上記のデルタの計算など、重みの偏微分を上から下へと順序よく計算していくことをバックワードパス(*backward pass*)と呼ばれる。この用法は、90年代からすでに浸透しており、2018年現在でも広く使われている（例：後ほど見るChainerの文法に入っている）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて、長々とニューラルネットワークの定式化と一つの最適化方法を見てきたが、これが一体どのように前節のリバースモード自動微分と関わるのだろうか。その答えは、先述の逆伝播法を賢く実装する方法がリバースモード自動微分そのものであり、後者のスペシャルケースとして捉えることができる。\n",
    "\n",
    "具体例を使って、先ほどのgeneralized delta ruleとの接点を見ていこう。下図のような単純なフィードフォワードニューラルネットワークを考える。\n",
    "\n",
    "<img src=\"img/nn_demo.png\"  alt=\"Hand-drawn NN example\" width=\"350\" height=\"245\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ユニットの添え字は絵に書いてある通り、$1,2,3,4,5,6$である。入力層を$u_{1},u_{2},u_{3}$と書く。残りは以下のように整理できる。\n",
    "\n",
    "\\begin{align*}\n",
    "u_{4} & = x_{4} = \\sum_{i \\to 4} w_{i4}u_{i}\\\\\n",
    "u_{5} & = x_{5} = \\sum_{i \\to 5} w_{i5}u_{i}\\\\\n",
    "u_{6} & = y_{4} = f_{4}(x_{4})\\\\\n",
    "u_{7} & = y_{5} = f_{5}(x_{5})\\\\\n",
    "u_{8} & = x_{6} = \\sum_{i \\to 5} w_{i6}u_{i}\\\\\n",
    "u_{9} & = y_{6} = f_{6}(x_{6})\n",
    "\\end{align*}\n",
    "\n",
    "例のデルタの計算は、自動微分を実行していくことで必然的に入手することになる。\n",
    "\n",
    "\\begin{align*}\n",
    "\\delta_{4} = \\frac{\\partial u_{9}}{\\partial u_{4}}, \\quad \\delta_{5} = \\frac{\\partial u_{9}}{\\partial u_{5}}, \\quad \\delta_{6} = \\frac{\\partial u_{9}}{\\partial u_{8}}\n",
    "\\end{align*}\n",
    "\n",
    "以上のように、リバースモード自動微分を正しく行うことで、デルタの再帰的な計算が自ずと行われることになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_bg\"></a>\n",
    "## Chainerを使ってみよう\n",
    "\n",
    "ごく簡単な紹介ではあったが、自動微分とニューラルネットワークの基本的な考え方を見て、パラメータの最適化を効率的に行う道筋が見えてきている。ただし、多種多様なネットワークアーキテクチャをカバーしながら、これを実装する作業は多大なる労力を要する。幸い、この作業を代行してくれる優秀なエンジニアがたくさんいるので、機械学習の手法のプロトタイプを開発するにあたって、彼らが作ったライブラリを用いることが賢明であろう。言語をPythonに限定しても、オープンソースで使い勝手の良いパッケージが多数ある。\n",
    "\n",
    "そのなかから、我々が使うのは、__Chainer__という国産のディープラーニングAPIである[<a href=\"https://docs.chainer.org/en/stable/\">link</a>]。日本国内では有名だが、世界ではTensorFlow, PyTorch, Caffeなどの人気APIの陰に隠れている現状である。それでも、Chainerは大変よくできており、実に簡明な枠組みであり、高い自由度と充実した機能性を誇る。また、複数のGPUを同時に駆使する仕組みも整備されており、ソフトウェア工学のバックグラウンドが浅い人でもすぐに使えるはずである。\n",
    "\n",
    "技術的な特徴としては、開発者がいう\"Define-by-Run\"の仕組みである。実行前にネットワーク構造を固定するのではなく、実行時にフォワードパスを行いながら、動的にネットワーク構造を求めていく[<a href=\"https://docs.chainer.org/en/stable/guides/define_by_run.html\">link</a>]。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainerの導入については、ドキュメンテーションで推奨されているように[<a href=\"https://docs.chainer.org/en/stable/install.html\">link</a>]、`chainer`を`pip`で入手していることを前提に以下の作業を進めていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの造設にあたって、以下の点を念頭に置いて、作業に入る。\n",
    "\n",
    "- ありとあらゆるデータやパラメータ（普段、Numpyの配列に格納するもの）は、`Variable`オブジェクトとする[<a href=\"https://docs.chainer.org/en/stable/guides/variables.html\">link</a>]。\n",
    "\n",
    "- `Variable`オブジェクトはNumpyの配列とほぼ同じように扱うことができる[<a href=\"https://docs.chainer.org/en/stable/reference/generated/chainer.Variable.html#chainer.Variable\">link</a>].\n",
    "\n",
    "- `FunctionNode`オブジェクトはcomputational graphにおけるノードに相当する。正確にいえば、微分可能な関数を実装したものである[<a href=\"https://docs.chainer.org/en/stable/reference/generated/chainer.FunctionNode.html#chainer-functionnode\">link</a>]。\n",
    "\n",
    "- 各々の`FunctionNode`に対して、フォワードパスに相当する`forward()`と、バックワードパスに相当する`backward()`という2つのメソッドを必ず整備する。\n",
    "\n",
    "- ノードの入力を所与として、それを処理する`FunctionNode`は、`apply()`というメソッドによって実行される。実行時には、computational graphにノードが追加され、フォワードパスの計算結果を返すという働きである。\n",
    "\n",
    "- モデルを作る上で、基本単位となるのは`Link`というオブジェクトである[<a href=\"https://docs.chainer.org/en/stable/reference/generated/chainer.Link.html#chainer.Link\">link</a>]。ある`FunctionNode`に基づく`Link`では、扱っている多数の`Variable`のうち、どれが観測データに相当し、どれが最適化の対象となるパラメータなのかを指定する。一部の変数を`Parameter`オブジェクトとして「登録」する作業が重要である。あと、`Link`では、`FunctionNode`を`__call__()`するためのメソッドも備えている。\n",
    "\n",
    "- `Chain`と呼ばれるオブジェクトは、`Link`から構成されるもので、モデルの全体あるいはその一部を表わすために使われる（注：`Chain`も`Link`である）[<a href=\"https://docs.chainer.org/en/stable/reference/generated/chainer.Chain.html#chainer-chain\">link</a>]。段取りとしては、`Chain`を作成するときに、その構成要素に相当する\"child links\"を登録しておく。\n",
    "\n",
    "さて、機械学習にあたっての学習作業について考えよう。Chainerの標準搭載の技術を中心としたやり方だと、以下のような手順になる。\n",
    "\n",
    "- モデルのオブジェクト（ほぼ例外なく`Chain`のサブクラス）を、`setup()`というメソッドによって`Optimizer`オブジェクトに渡しておく。\n",
    "\n",
    "- 反復的には以下の計算を行う。\n",
    "\n",
    "  - 実数値`Variable`を計算し、例として`loss`と呼ぶ。\n",
    "  \n",
    "  - `loss.backward()`を実行して逆伝播法によって、出力層に相当する`loss`から、入力層の重みまで、すべての`FunctionNode`オブジェクトの偏微分を行う。\n",
    "  \n",
    "  - 勾配を手に入れた上で、`Optimizer`オブジェクトの`update()`を使って、登録した`Parameter`を更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_exSimple\"></a>\n",
    "### 簡単な計算\n",
    "\n",
    "Chainerの基本的な働きを調べていくための簡単な事例をいくつか見ていこう。たとえば、以下の入出力の関係を考える。\n",
    "\n",
    "\\begin{align*}\n",
    "y = 2 x_{1}x_{2} + e^{x_{1}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import chainer as ch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients prior to calling y.backward():\n",
      "None\n",
      "None\n",
      "None\n",
      "\n",
      "Gradients after calling y.backward():\n",
      "[1.]\n",
      "[10.481689] ( answer = 10.481689 )\n",
      "[3.] ( answer = 3.0 )\n"
     ]
    }
   ],
   "source": [
    "touse_1 = 1.5\n",
    "touse_2 = 3.0\n",
    "\n",
    "x1 = ch.Variable(np.array([touse_1], dtype=np.float32))\n",
    "x2 = ch.Variable(np.array([touse_2], dtype=np.float32))\n",
    "y = 2*x1*x2 + math.exp(1)**x1\n",
    "\n",
    "# Note that all gradients start out empty.\n",
    "print(\"Gradients prior to calling y.backward():\")\n",
    "print(y.grad)\n",
    "print(x1.grad)\n",
    "print(x2.grad)\n",
    "\n",
    "# Now, compute the gradients of y.\n",
    "y.backward()\n",
    "print(\"\\nGradients after calling y.backward():\")\n",
    "print(y.grad)\n",
    "print(x1.grad, \"( answer =\",\n",
    "      np.float32(2*x2.data[0] + math.exp(1)**x1.data[0]),\n",
    "      \")\")\n",
    "print(x2.grad, \"( answer =\",\n",
    "      np.float32(2*x1.data[0] + 0),\n",
    "      \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちゃんと正解を出しているので、一安心である。この計算がどのように行われているか精密検査すべく、3つの層（$\\mathbf{u}_{0}, \\mathbf{u}_{1}, \\mathbf{u}_{2}$）に分ける。\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{u}_{0} & = (u_{0,1}, u_{0,2}) = (x_{1}, x_{2})\\\\\n",
    "\\mathbf{u}_{1} & = (u_{1,1}, u_{1,2}) = (u_{0,1}u_{0,2}, e^{u_{0,1}})\\\\\n",
    "\\mathbf{u}_{2} & = (u_{2,1}) = (2u_{1,1} + u_{1,2}).\n",
    "\\end{align*}\n",
    "\n",
    "上記から明らかなように、$\\mathbf{u}_{0}$を入力として、$\\mathbf{u}_{0} \\mapsto \\mathbf{u}_{1} \\mapsto \\mathbf{u}_{2}$という2つの変換を経て、最終的な出力を得る。以下では、これらの変換をそれぞれ実装した`U1`および`U2`という`FunctionNode`サブクラスを掲げている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U1(ch.function_node.FunctionNode):\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        u0, = inputs\n",
    "        u1 = np.array([u0[0,0]*u0[0,1], math.exp(1)**u0[0,0]],\n",
    "                      dtype=np.float32)\n",
    "        u1 = u1.reshape((1,2))\n",
    "        self.retain_inputs((0,))\n",
    "        return (u1,)\n",
    "\n",
    "    def backward(self, indices, grad_outputs):\n",
    "        \n",
    "        u0, = self.get_retained_inputs()\n",
    "        u0 = u0.data\n",
    "        gy, = grad_outputs # defaults to shape (1,2).\n",
    "        print(\"U1 gy:\", gy.data)\n",
    "        \n",
    "        # Compute the Jacobian.\n",
    "        J = np.array([u0[0,1], u0[0,0], math.exp(1)**u0[0,0], 0.0],\n",
    "                     dtype=np.float32).reshape((2,2))\n",
    "        J = ch.Variable(J)\n",
    "        \n",
    "        # Compute partial derivatives of interest.\n",
    "        gu0 = gy @ J # gy.dot(J)\n",
    "        print(\"U1 backward():\", gu0.data)\n",
    "        return (gu0,)\n",
    "\n",
    "def fn_u1(u0):\n",
    "    args = (u0,)\n",
    "    y, = U1().apply(args)\n",
    "    return y\n",
    "\n",
    "\n",
    "class U2(ch.function_node.FunctionNode):\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        u1, = inputs\n",
    "        u2 = np.array([2*u1[0,0]+u1[0,1]])\n",
    "        self.retain_inputs((0,))\n",
    "        return (u2,)\n",
    "\n",
    "    def backward(self, indices, grad_outputs):\n",
    "        \n",
    "        u1, = self.get_retained_inputs()\n",
    "        gy, = grad_outputs # defaults to shape (1,).\n",
    "        gy = gy.reshape((1,1))\n",
    "        gy = ch.functions.cast(gy, np.float32)\n",
    "        print(\"U2 gy:\", gy.data)\n",
    "        \n",
    "        # Compute the Jacobian.\n",
    "        J = np.array([2.0, 1.0], dtype=np.float32).reshape((1,2))\n",
    "        J = ch.Variable(J)\n",
    "        \n",
    "        # Compute partial derivatives of interest.\n",
    "        gu1 = gy @ J # gy.dot(J)\n",
    "        print(\"U2 backward():\", gu1.data)\n",
    "        return (gu1,)\n",
    "    \n",
    "def fn_u2(u1):\n",
    "    args = (u1,)\n",
    "    y, = U2().apply(args)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードパスのときに使う`forward()`メソッドはすぐに整備できる。定義どおりに実装するだけである。\n",
    "\n",
    "バックワードパスのときに使う`backward()`に関しては、Chainerの規定をしっかりと理解しておく必要がある（下図を参照）。\n",
    "\n",
    "<img src=\"img/chainer_backward_out.png\" alt=\"Chainer documentation on backward pass\" width=\"400\" height=\"250\" />\n",
    "\n",
    "要するに、各層の入出力の偏微分を整列させたヤコビ行列を計算し、`grad_outputs`から渡された係数をかけて、出力のインデックスについて足し合わせていく。上記の`U1`で計算している`J`の寸法は$(2 \\times 2)$で、次の形を取る。\n",
    "\n",
    "\\begin{align*}\n",
    "\\left[ \\frac{\\partial u_{1,i}}{\\partial u_{0,j}} \\right]_{i,j}, \\quad i = 1,2 \\quad j = 1,2.\n",
    "\\end{align*}\n",
    "\n",
    "`U2`で計算している`J`の寸法は$(1 \\times 2)$で、以下の形を取る。\n",
    "\n",
    "\\begin{align*}\n",
    "\\left[ \\frac{\\partial u_{2,i}}{\\partial u_{1,j}} \\right]_{i,j}, \\quad i = 1 \\quad j = 1,2.\n",
    "\\end{align*}\n",
    "\n",
    "リバースモード自動微分の話を思い出すと、次の再帰的な計算が重要であった。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{U}_{i} = \\bar{U}_{i+1} \\widetilde{J}_{i}\n",
    "\\end{align*}\n",
    "\n",
    "仮に層の数が$K$であるとして、これらの行列は以下のとおりである。\n",
    "\n",
    "\\begin{align*}\n",
    "\\bar{U}_{i} & = \\left[ \\frac{\\partial y_{j}}{\\partial u_{i,k}} \\right]_{j,k} \\quad (d_{K} \\times d_{i}), \\quad i = 0,1,\\ldots,K \\\\\n",
    "\\widetilde{J}_{i} & = \\left[ \\frac{\\partial u_{i+1,j}}{\\partial u_{i,k}} \\right]_{j,k} \\quad (d_{i+1} \\times d_{i}), \\quad i=0,1,\\ldots,K-1.\n",
    "\\end{align*}\n",
    "\n",
    "具体例に戻ると、$K=2$で、次元の数は$d_{0}=2, d_{1}=2, d_{2}=1$となる。以下のコードでは、`backward()`を我々の手作りノードに対して実行することで、その結果が元のコードの結果と完全に一致することがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of forward passes:\n",
      "y: 13.481689\n",
      "_y: 13.481688976287842\n",
      "\n",
      "Content of our backward() passes:\n",
      "U2 gy: [[1.]]\n",
      "U2 backward(): [[2. 1.]]\n",
      "U1 gy: [[2. 1.]]\n",
      "U1 backward(): [[10.481689  3.      ]]\n",
      "\n",
      "Gradient of (x1,x2): (10.481689, 3.0)\n",
      "Gradient of u0: (10.481689, 3.0)\n"
     ]
    }
   ],
   "source": [
    "touse_1 = 1.5\n",
    "touse_2 = 3.0\n",
    "\n",
    "# Original code.\n",
    "x1 = ch.Variable(np.array([touse_1], dtype=np.float32))\n",
    "x2 = ch.Variable(np.array([touse_2], dtype=np.float32))\n",
    "y = 2*x1*x2 + math.exp(1)**x1\n",
    "y = y.reshape((1,1))\n",
    "\n",
    "# Our custom reformulation.\n",
    "_u0 = np.array([touse_1, touse_2], dtype=np.float32).reshape((1,2))\n",
    "_u0 = ch.Variable(_u0)\n",
    "_u1 = fn_u1(u0=_u0)\n",
    "_y = fn_u2(u1=_u1)\n",
    "_y = _y.reshape((1,1))\n",
    "\n",
    "print(\"Output of forward passes:\")\n",
    "print(\"y:\", *y.data[0])\n",
    "print(\"_y:\", *_y.data[0])\n",
    "\n",
    "y.backward()\n",
    "print(\"\\nContent of our backward() passes:\")\n",
    "_y.backward()\n",
    "\n",
    "print(\"\\nGradient of (x1,x2):\", (x1.grad[0], x2.grad[0]))\n",
    "print(\"Gradient of u0:\", tuple(*_u0.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上の実行結果から明らかなように、2層目の`backward()`の結果が、下の1層目に`grad_outputs`という形で渡されている。期待どおりの計算である。\n",
    "\n",
    "__重要：__ 一般的な自動微分の枠組みでは、究極の計算目的である$\\bar{U}_{0}$が($d_{K} \\times d_{0}$)という形をとっても、何も問題はない。しかし、Chainerでは、必ず$d_{K}=1$と制限されていることに注意が必要である。これが事実であることは、明らかである。その理由は、Chainerのドキュメンテーションより、関数$f: \\mathbb{R}^{a} \\to \\mathbb{R}^{b}$のバックワードパス計算である`backward()`を実装する際、その出力が$\\mathbb{R}^{a}$でなければならないからである。\n",
    "\n",
    "しかし、数学的には、これは大丈夫であろうか。何を意味するものなのか。さらに検証していくために、先ほどの具体例に戻るが、今度はbackpropの対象を最終層の$\\mathbf{u}_{2} \\in \\mathbb{R}$ではなく、$\\mathbf{u}_{1} \\in \\mathbb{R}^{2}$とする（なお、$\\mathbf{u}_{0}$について微分を求めていることは変わらない）。そのためには、`grad_outputs`を、勾配を初期化する（`grad`を設定する）ことで、自分で渡す必要がある（以下のコードを参照）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1 gy: [[1. 1.]]\n",
      "U1 backward(): [[7.481689 1.5     ]]\n",
      "_u0.grad = (7.481689, 1.5)\n"
     ]
    }
   ],
   "source": [
    "_u0 = np.array([touse_1, touse_2], dtype=np.float32).reshape((1,2))\n",
    "_u0 = ch.Variable(_u0)\n",
    "_u1, = fn_u1(u0=_u0)\n",
    "_u1.grad = np.ones(_u1.shape, dtype=np.float32)\n",
    "_u1.backward()\n",
    "print(\"_u0.grad =\", tuple(*_u0.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すぐにわかるのは、$(1.0, 1.0)$に初期化したとき、計算結果が前と異なることである。その理由は、最後の変換が反映されていないからである。さて、今の例では、逆伝播法の対象となる関数の出力が多次元であることもあって、`backward()`の実行結果がヤコビ行列$\\partial \\mathbf{u}_{1} / \\partial \\mathbf{u}_{0}$となることを予想する読者がいるかもしれない。しかし、先述の理由により、これはあり得ないことである。勾配ベクトルしか保存されない。\n",
    "\n",
    "そうなると、数学的に、Chainerの中で一体何の関数が微分されているのだろうか。その答えは簡単で、以下のようなダミー関数が微分されているのである。\n",
    "\n",
    "\\begin{align*}\n",
    "f(\\mathbf{u}_{K}) = a_{1} u_{K,1} + \\cdots + a_{K} u_{K,d_{K}}\n",
    "\\end{align*}\n",
    "\n",
    "ここでの$\\mathbf{u}_{K}$は我々のモデルの最終層の出力に相当し、係数$(a_{1},\\ldots,a_{K})$は逆伝播に際して最初に使われる`grad_outputs`に相当する。上の例では、\n",
    "\n",
    "```\n",
    "_u1.grad = np.ones(_u1.shape, dtype=np.float32)\n",
    "```\n",
    "\n",
    "という初期化をしたのだが、これは上記のダミー関数で、$a_{1}=\\cdots=a_{K}=1$と置いたことにほかならない。\n",
    "\n",
    "上を要約すると、最終層の出力がスカラー値であれば、$d_{K}=1$なのですべてが直感通りである。一方の$d_{K} > 1$の場合、`grad`をどのように初期化するかによって、バックエンドに隠れているダミー関数の係数が変わるため、計算結果も変わってくる。ちなみに、$d_{K}=1$の場合は、わざわざ初期化する必要はなく、自動的に`grad`が1.0に初期化されるようになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__練習問題__\n",
    "\n",
    "0. 上の具体例で、2層目を自動微分の対象とした場合、`_u1.grad`を全部1.0にした結果、`_u1.backward()`を実行した結果が、もともとの`_u2.backward()`の実行結果と異なるものであった。どのように初期化すれば、前者が後者に一致するか。\n",
    "\n",
    "0. 上記の具体例を拡張すべく、たとえば3つか4つほどの層を持つように新しい演算を追加すること。上と同様に、自分で実装し、Chainerの計算結果が我々の数学的な予想と一致するかどうか確認すること。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_linreg\"></a>\n",
    "### 線形回帰での最小二乗法を再現\n",
    "\n",
    "練習の対象として、<a href=\"FrameworkIntro.ipynb\">前の章</a>では下記の学習機を取り上げた。\n",
    "\n",
    "> - データ：入力ベクトルと実数値の応答$x \\in \\mathbb{R}^{d}$, $y \\in \\mathbb{R}$.データセットの全体は$\\{(x_{1},y_{1}),\\ldots,(x_{n},y_{n})\\}$とする。\n",
    "> \n",
    "> - モデル：二乗誤差を用いた線形回帰モデル。つまり、$y = \\langle w^{\\ast}, x\\rangle + \\varepsilon$と仮定している。ロス関数は$L(w;x,y) = (y - \\langle w, x\\rangle)^{2}/2$で、勾配が$\\nabla L(w;x,y) = -(y-\\langle w, x\\rangle)x$である。\n",
    "> \n",
    "> - アルゴリズム：最急降下法を使って、固定したステップサイズ$\\alpha > 0$を用いる。数式で表わすと、$z_{i}=(x_{i},y_{i})$として以下の通りである。\n",
    "> \n",
    "> \\begin{align*}\n",
    "w_{(t+1)} \\gets w_{(t)} - \\alpha \\frac{1}{n} \\sum_{i=1}^{n}\\nabla L(w_{(t)}; z_{i}).\n",
    "\\end{align*}\n",
    "\n",
    "前の章で叩きだした各種のクラスなど、上記を実装するのに必要なものは全部`algorithms.py`, `models.py`, `dataclass.py`, and `helpers.py`に収めてある。ここでは、自作の学習機を、ChainerのAPIによって完全に再現することである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは必要なモジュールを`import`して、いわゆる\"fully connected linear layer\"を実装した`FunctionNode`を整備する（活性化関数を介さず、入力の線形和を取るだけ）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import chainer as ch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import algorithms\n",
    "import models\n",
    "import dataclass\n",
    "import helpers as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunctionNode sub-class, for implementing a fully connected linear layer.\n",
    "\n",
    "class LinearFunction(ch.function_node.FunctionNode):\n",
    "    '''\n",
    "    FunctionNode object, defined on Variable objects,\n",
    "    which is the basis for a linear transformation to\n",
    "    be wrapped up as a Link object.\n",
    "    \n",
    "    Take d-dimensional inputs x, and using array W of\n",
    "    shape (k,d), map this input to k outputs. That is,\n",
    "    we have a fully-connected layer with d input units\n",
    "    and k output units.\n",
    "    '''\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Forward computation for both CPU and GPU.\n",
    "        '''\n",
    "        \n",
    "        # Unpack the tuple of inputs.\n",
    "        if len(inputs) == 3:\n",
    "            x, W, b = inputs\n",
    "        else:\n",
    "            (x, W), b = inputs, None\n",
    "\n",
    "        y = x.dot(W.T).astype(x.dtype, copy=False)\n",
    "        \n",
    "        # Add a bias term, if relevant.\n",
    "        if b is not None:\n",
    "            y += b\n",
    "            \n",
    "        # Since backward() depends only on x and W,\n",
    "        # we need only retain these two.\n",
    "        self.retain_inputs((0,1))\n",
    "        \n",
    "        # Must return the output as a tuple.\n",
    "        return (y,)\n",
    "\n",
    "    def backward(self, indices, grad_outputs):\n",
    "        '''\n",
    "        General-purpose computation for both CPU/GPU.\n",
    "        '''\n",
    "        \n",
    "        x, W = self.get_retained_inputs()\n",
    "        gy, = grad_outputs # written as gamma in their docs.\n",
    "        \n",
    "        # Says that backward() must return a tuple, but\n",
    "        # looking at their source code for linear.py, it\n",
    "        # seems like lists are fine.\n",
    "        out = []\n",
    "        if 0 in indices:\n",
    "            gx = gy @ W # gy.dot(W)\n",
    "            out.append(ch.functions.cast(gx, x.dtype))\n",
    "        if 1 in indices:\n",
    "            gW = gy.T @ x # gy.T.dot(x)\n",
    "            out.append(ch.functions.cast(gW, W.dtype))\n",
    "        if 2 in indices:\n",
    "            # Summing here is simple: for n observations,\n",
    "            # gy has shape (n,k), where k is the number of\n",
    "            # layer outputs. Summing over axis=0 is summing\n",
    "            # over OBSERVATIONS, not over outputs.\n",
    "            gb = ch.functions.sum(gy, axis=0)\n",
    "            \n",
    "        # Return just the relevant gradients we appended.\n",
    "        return out\n",
    "\n",
    "\n",
    "def linear(x, W, b):\n",
    "    '''\n",
    "    A nice thin wrapper for our linear FunctionNode on\n",
    "    Variable objects.\n",
    "    '''\n",
    "    \n",
    "    if b is None:\n",
    "        args = (x, W)\n",
    "    else:\n",
    "        args = (x, W, b)\n",
    "    \n",
    "    # Don't forget to unpack from the tuple.\n",
    "    y, = LinearFunction().apply(args)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FunctionNode`の要点：\n",
    "\n",
    "- `forward()`はNumpyの配列だけで定義している（`Variable`でも良いが）。\n",
    "\n",
    "- `backward()`はサンプルの上で足しあわせていることに注意が必要。\n",
    "\n",
    "- さらに、`backward()`となると、`Variable`オブジェクトを前提とした実装にしなければならない（特別な演算記号`@`などがあるおは、そのためである）。\n",
    "\n",
    "次は、このノードに基づく`Link`オブジェクトを作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link object for our linear FunctionNode.\n",
    "\n",
    "class Linear(ch.Link):\n",
    "    '''\n",
    "    A Link class for our linear transformation, implemented\n",
    "    in the LinearFunction class.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 in_size, out_size,\n",
    "                 init_W=None, init_b=None,\n",
    "                 init_delta=None,\n",
    "                 nobias=False):\n",
    "        super(Linear, self).__init__()\n",
    "        \n",
    "        # Here we initialize and \"register\" the parameters\n",
    "        # of interest. This is critical because when we\n",
    "        # call __call__(x) and apply the underlying affine\n",
    "        # transformations to input x (both forward pass and\n",
    "        # backward pass), the optimization algorithms knows\n",
    "        # that we want to optimize W and maybe b, but not x.\n",
    "\n",
    "        with self.init_scope():\n",
    "            \n",
    "            # If provided an ndarray, use it.\n",
    "            if init_W is not None:\n",
    "                self.W = ch.Parameter(initializer=np.copy(init_W))\n",
    "            \n",
    "            # Else, use a built-in initializer.\n",
    "            else:\n",
    "                W_initializer = ch.initializers.Uniform(scale=init_delta,\n",
    "                                                        dtype=np.float32)\n",
    "                self.W = ch.Parameter(initializer=W_initializer,\n",
    "                                      shape=(out_size, in_size))\n",
    "            \n",
    "            if nobias:\n",
    "                self.b = None\n",
    "            else:\n",
    "                if init_b is not None:\n",
    "                    self.b = ch.Parameter(initializer=np.copy(init_b))\n",
    "                else:\n",
    "                    self.b = ch.Parameter(initializer=0,\n",
    "                                          shape=(out_size,))\n",
    "                \n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        This method actually applies the linear layer to\n",
    "        inputs x.\n",
    "        '''\n",
    "        return linear(x, self.W, self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この`Link`の定義でもっとも重要なのは、学習すべきパラメータを登録していることである。その段取りとしては、`init_scope()`なるコンテキストマネジャーを使って、指定したパラメータを属性(attributes)として格納しておく。この`Link`は先ほどの`LinearFunction`に基づくものであり、`__call__()`によって呼び出される。\n",
    "\n",
    "上記で区別しているのは、データの`x`と、学習すべきパラメータの`W`および`b`である。いずれも計算する必要があるのだが、最適化の対象となるのは後者のみであるから、明確に区別することがきわめて重要である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、`Chain`オブジェクトを先ほどの`Link`から造設していく。`Chain`の定義が`Link`の定義に酷似しているのは、`Chain`自体が`Link`でもあるからである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain object, composed of Link objects. This is a proper model in the\n",
    "# sense that it can be fed to optimizers.\n",
    "\n",
    "class Chain_LinReg(ch.Chain):\n",
    "    '''\n",
    "    Perhaps the simplest possible model, a\n",
    "    feed-forward neural network without any\n",
    "    hidden layers. Just one, fully-connected\n",
    "    linear layer, aka a classical linear\n",
    "    regression model, with arbitrary number\n",
    "    of outputs.\n",
    "    \n",
    "    out_l0: number of outputs from layer 0.\n",
    "    out_l1: number of outputs from layer 1.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 out_l0,\n",
    "                 out_l1,\n",
    "                 init_W=None,\n",
    "                 init_b=None,\n",
    "                 init_delta=1.0,\n",
    "                 nobias=False):\n",
    "        super(Chain_LinReg, self).__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.l1 = Linear(in_size=out_l0,\n",
    "                             out_size=out_l1,\n",
    "                             init_W=init_W,\n",
    "                             init_b=init_b,\n",
    "                             init_delta=init_delta,\n",
    "                             nobias=True)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.l1(x) # parameters are managed by Links.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Link`オブジェクトがパラメータを登録するのと同様に、`Chain`オブジェクトは\"child links\"を登録し、属性として格納する（ここもやはり`init_scope()`なるコンテキストマネジャーを使う）。\n",
    "\n",
    "我々が扱っている今回の具体例では、モデルが至ってシンプルなので、長さ`out_l0`のベクトルを入力として受け取り、たった1回の行列の掛け算を`Linear`で実行し、出力する。その実行結果の長さが`out_l1`である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我々としてもっとも重要なのは、勾配降下法などに際して、Chainerが予想通りに偏微分を計算してくれているかどうかである。丁寧にこれを検証するために、同一のデータセットに対して、自作の学習機とChainerによって作った学習機を両方試してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup.\n",
    "\n",
    "# Data-related.\n",
    "data = dataclass.DataSet() # Initialize one data object; will be re-populated at each trial.\n",
    "n = 500 # sample size\n",
    "d = 2 # number of parameters\n",
    "init_delta = 5.0 # controls support of random initialization\n",
    "num_trials = 250 # number of independent random trials to conduct\n",
    "cov_X = np.eye(d) # covariance matrix of the inputs.\n",
    "\n",
    "w_star = np.ones(d).reshape((d,1)) # vector specifying true model\n",
    "\n",
    "# Algorithm-related.\n",
    "m_idx_todo = [0,1] # let's us manually pick and choose which methods to evaluate.\n",
    "t_max = 30 # termination condition; maximum number of iterations.\n",
    "thres = -1.0 # termination condition; if negative, runs for max iterations.\n",
    "\n",
    "def alpha_fixed(t, val): # step-size callback function.\n",
    "    return val\n",
    "def make_step(u):\n",
    "    def mystep(t, model=None, data=None, newdir=None):\n",
    "        return alpha_fixed(t=t, val=u)\n",
    "    return mystep\n",
    "alphaval = 0.25\n",
    "\n",
    "# Clerical.\n",
    "mth_names = [\"gd\", \"gd-ch\"]\n",
    "num_mths = len(mth_names)\n",
    "mth_colours = [\"black\", \"blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make choice of additive noise distribution (un-comment your choice).\n",
    "#paras = {\"name\": \"norm\", \"shift\": 0.0, \"scale\": 20.0}\n",
    "paras = {\"name\": \"lnorm\", \"meanlog\": 0.0, \"sdlog\": 1.75}\n",
    "\n",
    "# Put together risk function.\n",
    "def risk(w):\n",
    "    mean_noise, var_noise = hlp.noise_risk(paras=paras)\n",
    "    return hlp.riskMaker(w=w, A=cov_X, b=math.sqrt(var_noise), w_star=w_star)\n",
    "risk_star = risk(w=w_star) # optimal risk value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the algorithms.\n",
    "\n",
    "# Prepare storage for performance metrics.\n",
    "riskvals = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "loss_tr = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "truedist = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "\n",
    "# Loop over trials.\n",
    "for tri in range(num_trials):\n",
    "    \n",
    "    # Generate new data (with *centered* noise).\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n,d))\n",
    "    noise = hlp.noise_data(n=n, paras=paras)\n",
    "    y = np.dot(X, w_star) + noise\n",
    "    data.init_tr(X=X, y=y)\n",
    "    \n",
    "    # Data for Chainer model.\n",
    "    Z = ch.datasets.TupleDataset(np.float32(X),\n",
    "                                 np.float32(y))\n",
    "    \n",
    "    # Initial weight settings.\n",
    "    w_init = w_star + np.random.uniform(low=-init_delta, high=init_delta, size=d).reshape((d,1))\n",
    "    w_init = np.float32(w_init)\n",
    "    \n",
    "    # Initialize models (hand-built).\n",
    "    mod_learner = models.LinearL2(data=data)\n",
    "    risk_star = risk(w=w_star) # optimal risk value.\n",
    "    loss_star = np.mean(mod_learner.l_tr(w=w_star, data=data))\n",
    "    \n",
    "    # Initialize models (Chainer-based).\n",
    "    mod_chainer = Chain_LinReg(out_l0=d,\n",
    "                               out_l1=1,\n",
    "                               init_W=w_init.T,\n",
    "                               init_b=None,\n",
    "                               init_delta=init_delta,\n",
    "                               nobias=True)\n",
    "    \n",
    "    # Initialize algorithms (hand-built).\n",
    "    al_gd = algorithms.Algo_GD(w_init=w_init,\n",
    "                               step=make_step(alphaval),\n",
    "                               t_max=t_max,\n",
    "                               thres=thres,\n",
    "                               store=True,\n",
    "                               lamreg=None)\n",
    "    \n",
    "    # Initialize algorithms (Chainer-based).\n",
    "    opt_chainer = ch.optimizers.SGD(lr=alphaval)\n",
    "    opt_chainer.setup(mod_chainer) # pass model!\n",
    "\n",
    "    \n",
    "    # Run all algorithms and save their performance.\n",
    "    \n",
    "    ## ERM-GD.\n",
    "    mthidx = 0\n",
    "    if mthidx in m_idx_todo:        \n",
    "        idx = 0\n",
    "        for mystep in al_gd:\n",
    "            al_gd.update(model=mod_learner, data=data)\n",
    "            # Record performance\n",
    "            loss_tr[tri,idx,mthidx] = np.mean(mod_learner.l_tr(w=al_gd.w, data=data))-loss_star\n",
    "            riskvals[tri,idx,mthidx] = risk(w=al_gd.w)-risk_star\n",
    "            truedist[tri,idx,mthidx] = np.linalg.norm(w_star-al_gd.w)-0\n",
    "            idx += 1\n",
    "        \n",
    "        \n",
    "    ## Replication of ERM using Chainer.\n",
    "    mthidx = 1\n",
    "    if mthidx in m_idx_todo:\n",
    "        idx = 0\n",
    "        iter_train = ch.iterators.SerialIterator(dataset=Z,\n",
    "                                                 batch_size=n, # thus SGD=GD; deterministic.\n",
    "                                                 repeat=True,\n",
    "                                                 shuffle=False)\n",
    "        while iter_train.epoch < t_max:\n",
    "\n",
    "            # Get our mini-batch.\n",
    "            Z_batch = iter_train.next()\n",
    "            X_batch, y_batch = ch.dataset.concat_examples(Z_batch)\n",
    "\n",
    "            # Predictions.\n",
    "            prediction_tr = mod_chainer(X_batch)\n",
    "\n",
    "            # Loss computations (will feed the grad computations).\n",
    "            loss = ch.functions.mean_squared_error(prediction_tr, y_batch) / 2.0\n",
    "            #old_loss = np.mean(mod_learner.l_tr(w=mod_chainer.l1.W.data.T, data=data))\n",
    "            #print(\"old versus new:\")\n",
    "            #print(loss, old_loss)\n",
    "            loss_star = np.mean(mod_learner.l_tr(w=w_star, data=data))\n",
    "            \n",
    "            # Gradient computations.\n",
    "            mod_chainer.cleargrads()\n",
    "            loss.grad = np.ones(loss.data.shape, dtype=np.float32)\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter updates.\n",
    "            opt_chainer.update()\n",
    "\n",
    "            # Record performance\n",
    "            loss_tr[tri,idx,mthidx] = np.mean(mod_learner.l_tr(w=mod_chainer.l1.W.data.T, data=data))-loss_star\n",
    "            riskvals[tri,idx,mthidx] = risk(w=mod_chainer.l1.W.data.T)-risk_star\n",
    "            truedist[tri,idx,mthidx] = np.linalg.norm(w_star-mod_chainer.l1.W.data.T)-0\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "# Finally, take statistics of the performance metrics over all trials.\n",
    "ave_loss_tr = np.mean(loss_tr, axis=0)\n",
    "ave_riskvals = np.mean(riskvals, axis=0)\n",
    "ave_truedist = np.mean(truedist, axis=0)\n",
    "sd_loss_tr = np.std(loss_tr, axis=0)\n",
    "sd_riskvals = np.std(riskvals, axis=0)\n",
    "sd_truedist = np.std(truedist, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要点：\n",
    "\n",
    "- `loss.grads`を手動で初期化していないことは、微分の対象となるものがスカラーだからである（先述）。\n",
    "\n",
    "- 反復的に更新しているが、複数ステージにわたって勾配情報が加算されていくと誤った計算結果につながるため、必ず`cleargrads()`を実行すること。これは`mod_chainer`と呼んでいる`Chain`のメソッドである。\n",
    "\n",
    "- 今回使っている`Optimizer`オブジェクト（`opt_chainer`）がパラメータの更新をChainer側でさばいてくれている。学習したい`Parameter`はすべて`mod_chainer`で登録していること、また`mod_chainer`が`opt_chainer`に渡されていることなどを踏まえると、最適化担当はしかるべき情報をもらっていることがわかる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualization of performance.\n",
    "\n",
    "tvals = np.arange(t_max)+1 # better to start from the first update.\n",
    "\n",
    "# Average over trials.\n",
    "myfig = plt.figure(figsize=(15,5))\n",
    "\n",
    "ax_loss_tr = myfig.add_subplot(1, 3, 1)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_loss_tr[:,m]\n",
    "    err = sd_loss_tr[:,m]\n",
    "    ax_loss_tr.plot(tvals, vals, color=mth_colours[m], label=mth_names[m])\n",
    "    #ax_loss_tr.errorbar(tvals, vals, yerr=err, fmt='-o', col=mth_colours[m], label=mth_names[m])\n",
    "    ax_loss_tr.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Excess empirical risk\")\n",
    "\n",
    "ax_riskvals = myfig.add_subplot(1, 3, 2)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_riskvals[:,m]\n",
    "    err = sd_riskvals[:,m]\n",
    "    err_log = err / vals\n",
    "    ax_riskvals.semilogy(tvals, vals, \"-o\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_riskvals.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Excess risk\")\n",
    "\n",
    "ax_variation = myfig.add_subplot(1, 3, 3)\n",
    "for m in m_idx_todo:\n",
    "    vals = sd_riskvals[:,m]\n",
    "    ax_variation.plot(tvals, vals, \"-o\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_variation.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Variation of risk across samples\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__練習問題__\n",
    "\n",
    "0. 上記の具体例では、終了条件として`iter_train.epoch`を使っている。Chainerでは、epochが何をしているか説明すること。ミニバッチの大きさを$n$より小さな整数にした場合、より速く終了することを確かめること。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_exNonLin\"></a>\n",
    "### 任意の活性化関数を用いた非線形モデル\n",
    "\n",
    "前の節に続き、線形モデルから単純な非線形モデルへと拡張していく。入力$\\mathbf{x} \\in \\mathbb{R}^{d_{0}}$を所与として、$\\mathbf{y} = (y_{1},\\ldots,y_{d_{1}})$への変換を次のように表記する。\n",
    "\n",
    "- 線形： $y_{j} = \\mathbf{w}_{j}^{T}\\mathbf{x} + b_{j}$\n",
    "\n",
    "- 非線形： $y_{j} = \\phi(\\mathbf{w}_{j}^{T}\\mathbf{x} + b_{j})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの変換を実装した`FunctionNode`の`backward()`メソッドでは、寸法$(d_{1} \\times d_{0})$のヤコビ行列$\\partial \\mathbf{y} / \\partial \\mathbf{w}$を計算し、寸法($1 \\times d_{1}$)の`grad_outputs`との行列掛け算をする必要がある。ヤコビ行列自体はすぐに計算できる。線形の場合：\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial y_{i}}{\\partial w_{j,k}} =\n",
    "\\begin{cases}\n",
    "0, & i \\neq j\\\\\n",
    "x_{k}, & i = j\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "非線形の場合も同様に：\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial y_{i}}{\\partial w_{j,k}} =\n",
    "\\begin{cases}\n",
    "0, & i \\neq j\\\\\n",
    "\\phi^{\\prime}(\\mathbf{w}_{j}^{T}\\mathbf{x} + b_{j}) \\, x_{k}, & i = j.\n",
    "\\end{cases}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで、`grad_outputs`から渡されたものを$(\\gamma_{1},\\ldots,\\gamma_{d_{1}})$と書くことにすると、我々の`backward()`が以下の計算結果を返さなければならない。\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^{d_{1}} \\gamma_{i} \\frac{\\partial y_{i}}{\\partial w_{j,k}} = \\gamma_{j} \\frac{\\partial y_{j}}{\\partial w_{j,k}} = \\gamma_{j} \\, \\phi^{\\prime}(\\mathbf{w}_{j}^{T}\\mathbf{x} + b_{j}) \\, x_{k}\n",
    "\\end{align*}\n",
    "\n",
    "インデックスの取る値は$j=1,\\ldots,d_{1}$と$k=1,\\ldots,d_{0}$である。したがって、出力するのは、容易に求められる以下のベクトルである。\n",
    "\n",
    "\\begin{align*}\n",
    "\\left( \\gamma_{1} \\, \\phi^{\\prime}(\\mathbf{w}_{1}^{T}\\mathbf{x} + b_{1}), \\ldots, \\gamma_{d_{1}} \\, \\phi^{\\prime}(\\mathbf{w}_{d_{1}}^{T}\\mathbf{x} + b_{d_{1}}) \\right).\n",
    "\\end{align*}\n",
    "\n",
    "以下で非線形モデルを実装するとき、このベクトルは`gy_nl`に相当する(以前として$1 \\times d_{1}$の二次元配列)。$\\mathbf{b}$や$\\mathbf{x}$についての偏微分もまったく同様に線形から非線形へと拡張することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import chainer as ch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import models\n",
    "import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearFunction(ch.function_node.FunctionNode):\n",
    "    '''\n",
    "    The Function object defined on Variable objects\n",
    "    that is the basis for a linear transformation to\n",
    "    be wrapped up as a Link object. The basic idea is\n",
    "    that we have d-dimensional inputs x, and the array\n",
    "    called \"W\" is of the shape (k, d). Thus the output\n",
    "    of x.dot(W.T) is that of precisely k \"units\".\n",
    "    '''\n",
    "    \n",
    "    def f_nonlin(self, u):\n",
    "        '''\n",
    "        Non-linear activation function.\n",
    "        Here: vectorized logistic function.\n",
    "        '''\n",
    "        return 1 / (1+np.exp(-u))\n",
    "    \n",
    "    def df_nonlin(self, u):\n",
    "        '''\n",
    "        First-order derivative of non-linear\n",
    "        activation function.\n",
    "        Here: vectorized logistic function deriv.\n",
    "        '''\n",
    "        y = self.f_nonlin(u=u)\n",
    "        return y * (1-y)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        Forward computation for both CPU and GPU.\n",
    "        '''\n",
    "        \n",
    "        # Unpack the tuple of inputs.\n",
    "        if len(inputs) == 3:\n",
    "            x, W, b = inputs\n",
    "        else:\n",
    "            (x, W), b = inputs, None\n",
    "\n",
    "        y = x.dot(W.T).astype(x.dtype, copy=False)\n",
    "        \n",
    "        # Add a bias term, if relevant.\n",
    "        if b is not None:\n",
    "            y += b\n",
    "            self.retain_inputs((0,1,2))\n",
    "        else:\n",
    "            self.retain_inputs((0,1))\n",
    "            \n",
    "        # Finally the non-linear activation.\n",
    "        y = self.f_nonlin(y)\n",
    "        \n",
    "        # Must return the output as a tuple.\n",
    "        return (y,)\n",
    "    \n",
    "\n",
    "    def backward(self, indices, grad_outputs):\n",
    "        '''\n",
    "        Backward computation for both CPU and GPU.\n",
    "        '''\n",
    "        \n",
    "        if len(indices)==3:\n",
    "            x, W, b = self.get_retained_inputs()\n",
    "        else:\n",
    "            (x, W), b = self.get_retained_inputs(), ch.Variable(None)\n",
    "        \n",
    "        y = x.data.dot(W.data.T).astype(x.dtype, copy=False) # (n,k)\n",
    "        #y, = self.forward(inputs=(x.data, W.data, b.data)) # (n,k). Needed for grad comps.\n",
    "        gy, = grad_outputs # written as gamma in their docs.\n",
    "        gy_nl = ch.Variable(self.df_nonlin(y)) * gy # to account for non-linearity.\n",
    "        \n",
    "        # Says that backward() must return a tuple, but\n",
    "        # looking at their source code for linear.py, it\n",
    "        # seems like lists are fine.\n",
    "        out = []\n",
    "        if 0 in indices:\n",
    "            gx = gy_nl @ W # gy_nl.dot(W)\n",
    "            out.append(ch.functions.cast(gx, x.dtype))\n",
    "        if 1 in indices:\n",
    "            gW = gy_nl.T @ x # gy_nl.T.dot(x)\n",
    "            out.append(ch.functions.cast(gW, W.dtype))\n",
    "        if 2 in indices:\n",
    "            # Summing here is simple: for n observations,\n",
    "            # gy has shape (n,k), where k is the number of\n",
    "            # layer outputs. Summing over axis=0 is summing\n",
    "            # over OBSERVATIONS, not over outputs.\n",
    "            gb = ch.functions.sum(gy_nl, axis=0) # gy_nl.sum(axis=0)\n",
    "            out.append(ch.functions.cast(gb, b.dtype))\n",
    "            \n",
    "        # Return just the relevant gradients we appended.\n",
    "        return out\n",
    "\n",
    "\n",
    "def nonlinear(x, W, b):\n",
    "    '''\n",
    "    A nice thin wrapper for our non-linear FunctionNode on\n",
    "    Variable objects.\n",
    "    '''\n",
    "    if b is None:\n",
    "        args = (x, W)\n",
    "    else:\n",
    "        args = (x, W, b)\n",
    "        \n",
    "    y, = NonLinearFunction().apply(args)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinear(ch.Link):\n",
    "    '''\n",
    "    A Link class for our non-linear transformation, implemented\n",
    "    in the NonLinearFunction class.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 in_size, out_size,\n",
    "                 init_W=None, init_b=None,\n",
    "                 init_delta=None,\n",
    "                 nobias=False):\n",
    "        super(NonLinear, self).__init__()\n",
    "        \n",
    "        # Here we initialize and \"register\" the parameters\n",
    "        # of interest. This is critical because when we\n",
    "        # call __call__(x) and apply the underlying affine\n",
    "        # transformations to input x (both forward pass and\n",
    "        # backward pass), the optimization algorithm knows\n",
    "        # that we want to optimize W and maybe b, but not x.\n",
    "\n",
    "        with self.init_scope():\n",
    "            \n",
    "            # If provided an ndarray, use it.\n",
    "            if init_W is not None:\n",
    "                self.W = ch.Parameter(initializer=np.copy(init_W))\n",
    "            \n",
    "            # Else, use a built-in initializer.\n",
    "            else:\n",
    "                W_initializer = ch.initializers.Uniform(scale=init_delta,\n",
    "                                                        dtype=np.float32)\n",
    "                self.W = ch.Parameter(initializer=W_initializer,\n",
    "                                      shape=(out_size, in_size))\n",
    "            \n",
    "            if nobias:\n",
    "                self.b = None\n",
    "            else:\n",
    "                if init_b is not None:\n",
    "                    self.b = ch.Parameter(initializer=np.copy(init_b))\n",
    "                else:\n",
    "                    self.b = ch.Parameter(initializer=0,\n",
    "                                          shape=(out_size,))\n",
    "                \n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        This method actually applies the linear layer to\n",
    "        inputs x.\n",
    "        '''\n",
    "        return nonlinear(x, self.W, self.b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chain_NonLinReg(ch.Chain):\n",
    "    '''\n",
    "    A simple feed-forward neural network that has\n",
    "    one hidden layer, with non-linear activation.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 out_l0,\n",
    "                 out_l1,\n",
    "                 out_l2,\n",
    "                 init_W1=None,\n",
    "                 init_W2=None,\n",
    "                 init_delta=1.0,\n",
    "                 nobias=False):\n",
    "        super(Chain_NonLinReg, self).__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            self.l1 = NonLinear(in_size=out_l0,\n",
    "                                out_size=out_l1,\n",
    "                                init_W=init_W1,\n",
    "                                init_b=None,\n",
    "                                init_delta=init_delta,\n",
    "                                nobias=True)\n",
    "            \n",
    "            self.l2 = models.Linear(in_size=out_l1,\n",
    "                                    out_size=out_l2,\n",
    "                                    init_W=init_W2,\n",
    "                                    init_b=None,\n",
    "                                    init_delta=init_delta,\n",
    "                                    nobias=True)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Chain_Logistic(ch.Chain):\n",
    "    '''\n",
    "    For pre-built activation functions, we can just pass\n",
    "    linear layers through them, and Chainer does the rest.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 out_l0,\n",
    "                 out_l1,\n",
    "                 out_l2,\n",
    "                 init_W1=None,\n",
    "                 init_W2=None,\n",
    "                 init_delta=1.0,\n",
    "                 nobias=False):\n",
    "        super(Chain_Logistic, self).__init__()\n",
    "        \n",
    "        with self.init_scope():\n",
    "            \n",
    "            self.l1 = models.Linear(in_size=out_l0,\n",
    "                                    out_size=out_l1,\n",
    "                                    init_W=init_W1,\n",
    "                                    init_b=None,\n",
    "                                    init_delta=init_delta,\n",
    "                                    nobias=True)\n",
    "            \n",
    "            self.l2 = models.Linear(in_size=out_l1,\n",
    "                                    out_size=out_l2,\n",
    "                                    init_W=init_W2,\n",
    "                                    init_b=None,\n",
    "                                    init_delta=init_delta,\n",
    "                                    nobias=True)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        out = ch.functions.sigmoid(self.l1(x)) # logistic sigmoid.\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs (us vs. them), n = 3 samples:\n",
      "-----\n",
      "[0.87012995 3.47568442]\n",
      "[0.87012995 3.47568442]\n",
      "-----\n",
      "[0.24158042 2.7378033 ]\n",
      "[0.24158042 2.7378033 ]\n",
      "-----\n",
      "[2.52917936 8.49487156]\n",
      "[2.52917936 8.49487156]\n",
      "-----\n",
      "Gradient comparison:\n",
      "--\n",
      "us: [[ 1.2020643 -1.8916731]\n",
      " [ 2.1698744 -2.6294236]\n",
      " [ 3.217658  -3.2660933]\n",
      " [ 4.058814  -3.896445 ]]\n",
      "them: [[ 1.2020643 -1.8916731]\n",
      " [ 2.1698744 -2.6294236]\n",
      " [ 3.217658  -3.2660933]\n",
      " [ 4.058814  -3.896445 ]]\n",
      "--\n",
      "us: [[0.9181247  0.6589377  0.58746296 0.602342  ]\n",
      " [0.9181247  0.6589377  0.58746296 0.602342  ]]\n",
      "them: [[0.9181247  0.6589377  0.58746296 0.602342  ]\n",
      " [0.9181247  0.6589377  0.58746296 0.602342  ]]\n",
      "--\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "d0, d1, d2 = 2, 4, 2\n",
    "\n",
    "init_W1 = np.arange(d0*d1, dtype=np.float32).reshape((d1,d0))\n",
    "init_W2 = np.arange(d1*d2, dtype=np.float32).reshape((d2,d1))\n",
    "\n",
    "mod_us = Chain_NonLinReg(out_l0=d0, out_l1=d1, out_l2=d2,\n",
    "                         init_W1=init_W1, init_W2=init_W2)\n",
    "mod_them = Chain_Logistic(out_l0=d0, out_l1=d1, out_l2=d2,\n",
    "                         init_W1=init_W1, init_W2=init_W2)\n",
    "\n",
    "X = np.random.normal(loc=0.0, scale=1.0, size=(n,d0))\n",
    "\n",
    "y_us = mod_us(X)\n",
    "y_them = mod_them(X)\n",
    "\n",
    "print(\"Outputs (us vs. them), n =\", n, \"samples:\")\n",
    "print(\"-----\")\n",
    "for i in range(n):\n",
    "    print(y_us.data[i,:])\n",
    "    print(y_them.data[i,:])\n",
    "    print(\"-----\")\n",
    "    \n",
    "# Gradient compuations.\n",
    "y_us.grad = np.ones(y_us.data.shape, dtype=y_us.data.dtype)\n",
    "y_them.grad = np.ones(y_them.data.shape, dtype=y_them.data.dtype)\n",
    "mod_us.cleargrads()\n",
    "mod_them.cleargrads()\n",
    "y_us.backward()\n",
    "y_them.backward()\n",
    "\n",
    "print(\"Gradient comparison:\")\n",
    "print(\"--\")\n",
    "diff_sq = 0\n",
    "zipped = zip(mod_us.params(), mod_them.params())\n",
    "for p_us, p_them in zipped:\n",
    "    grad_us = p_us.grad\n",
    "    grad_them = p_them.grad\n",
    "    diff_sq += np.linalg.norm(grad_us-grad_them)**2\n",
    "    print(\"us:\", grad_us)\n",
    "    print(\"them:\", grad_them)\n",
    "    print(\"--\")\n",
    "    \n",
    "print(\"Difference:\", math.sqrt(diff_sq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要点：\n",
    "\n",
    " - 活性化関数がChainerの`functions`モジュールに標準搭載されている場合は、わざわざ自分の`NonLinearFunction`を作る必要はなく、線形`Link`をそのまま非線形変換に渡すだけで済むのである。\n",
    " \n",
    " - 一方、Chainerにあらかじめ用意されていない活性化関数を使いたいときは、上記の段取りを模倣することで、任意の微分可能な非線形変換に対応した`Link`を整備することが容易にできる。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_lgstreg\"></a>\n",
    "### 多クラスのロジスティック回帰の自作と比較\n",
    "\n",
    "<a href=\"Classifiers.ipynb\">前の章</a>では、自作のロジスティック回帰を用意した。ここではChainerを使ったロジスティック回帰の学習機を作る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tables\n",
    "import numpy as np\n",
    "import chainer as ch\n",
    "import multiprocessing as mltp\n",
    "\n",
    "import dataclass\n",
    "import algorithms\n",
    "import helpers as hlp\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental setup.\n",
    "\n",
    "task_name = \"iris\" # SET BY HAND.\n",
    "init_delta = 5.0 # controls support of random initialization\n",
    "num_trials = 250 # number of independent random trials to conduct\n",
    "\n",
    "# Prepare a results folder, if doesn't already exist.\n",
    "hlp.makedir_safe(os.path.join(\"results\", task_name))\n",
    "\n",
    "# Establish file connection.\n",
    "toread = os.path.join(\"data\", task_name, \"data.h5\")\n",
    "f = tables.open_file(toread, mode=\"r\")\n",
    "\n",
    "# Data for the hand-built model.\n",
    "data = dataclass.DataSet()\n",
    "data.init_tr(X=f.root.train.inputs.read(),\n",
    "             y=f.root.train.labels.read())\n",
    "data.init_te(X=f.root.test.inputs.read(),\n",
    "             y=f.root.test.labels.read())\n",
    "\n",
    "# Data for Chainer model.\n",
    "Z_tr = ch.datasets.TupleDataset(np.float32(f.root.train.inputs.read()),\n",
    "                                np.int8(f.root.train.labels.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup.\n",
    "\n",
    "n, numfeats = data.X_tr.shape # sample size, number of features.\n",
    "nc = 3 # number of classes\n",
    "d = (nc-1)*numfeats\n",
    "\n",
    "# Algorithm-related.\n",
    "m_idx_todo = [0,1] # let's us manually pick and choose which methods to evaluate.\n",
    "t_max = 100 # termination condition; maximum number of iterations.\n",
    "thres = -1.0 # termination condition; if negative, runs for max iterations.\n",
    "\n",
    "def alpha_fixed(t, val): # step-size callback function.\n",
    "    return val\n",
    "def make_step(u):\n",
    "    def mystep(t, model=None, data=None, newdir=None):\n",
    "        return alpha_fixed(t=t, val=u)\n",
    "    return mystep\n",
    "alphaval = 0.1\n",
    "\n",
    "# Clerical.\n",
    "mth_names = [\"lgstReg\", \"lgstReg-ch\"]\n",
    "num_mths = len(mth_names)\n",
    "mth_colours = [\"black\", \"blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the algorithms.\n",
    "\n",
    "# Prepare storage for performance metrics.\n",
    "riskvals = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "loss_tr = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "\n",
    "# Loop over trials.\n",
    "for tri in range(num_trials):\n",
    "    \n",
    "    # Initial weight settings.\n",
    "    w_init = np.random.uniform(low=-init_delta, high=init_delta, size=d).reshape((d,1))\n",
    "    w_init = np.float32(w_init)\n",
    "    W_init_ch = np.concatenate((w_init.flatten().reshape((nc-1,numfeats)),\n",
    "                                np.zeros((1,numfeats), dtype=np.float32)),\n",
    "                               axis=0) # add an extra row of zeros to start.\n",
    "    \n",
    "    # Initialize models (hand-built).\n",
    "    mod_learner = models.LogisticReg(data=data)\n",
    "    risk_star = 0 # lower bound on optimal risk value.\n",
    "    loss_star = 0\n",
    "    \n",
    "    # Initialize models (Chainer-based).\n",
    "    mod_chainer = Chain_LinReg(out_l0=numfeats,\n",
    "                               out_l1=nc,\n",
    "                               init_W=W_init_ch,\n",
    "                               init_b=None,\n",
    "                               init_delta=init_delta,\n",
    "                               nobias=True)\n",
    "    \n",
    "    # Initialize algorithms (hand-built).\n",
    "    al_gd = algorithms.Algo_GD(w_init=w_init,\n",
    "                               step=make_step(alphaval),\n",
    "                               t_max=t_max,\n",
    "                               thres=thres,\n",
    "                               store=True,\n",
    "                               lamreg=None)\n",
    "    \n",
    "    # Initialize algorithms (Chainer-based).\n",
    "    opt_chainer = ch.optimizers.SGD(lr=alphaval)\n",
    "    opt_chainer.setup(mod_chainer) # pass model!\n",
    "\n",
    "    \n",
    "    # Run all algorithms and save their performance.\n",
    "    \n",
    "    ## ERM-GD.\n",
    "    mthidx = 0\n",
    "    if mthidx in m_idx_todo:        \n",
    "        idx = 0\n",
    "        for mystep in al_gd:\n",
    "            al_gd.update(model=mod_learner, data=data)\n",
    "            # Record performance\n",
    "            loss_tr[tri,idx,mthidx] = np.mean(mod_learner.l_tr(w=al_gd.w, data=data))-loss_star\n",
    "            y_est_te = mod_learner.classify(w=al_gd.w, X=data.X_te)\n",
    "            riskvals[tri,idx,mthidx] = mod_learner.class_perf(y_est=y_est_te,\n",
    "                                                              y_true=data.y_te)[\"rate\"]-risk_star\n",
    "            idx += 1\n",
    "        \n",
    "    ## Replication of ERM using Chainer.\n",
    "    mthidx = 1\n",
    "    if mthidx in m_idx_todo:\n",
    "        idx = 0\n",
    "        iter_train = ch.iterators.SerialIterator(dataset=Z_tr,\n",
    "                                                 batch_size=n, # thus SGD=GD; deterministic.\n",
    "                                                 repeat=True,\n",
    "                                                 shuffle=False)\n",
    "        while iter_train.epoch < t_max:\n",
    "\n",
    "            # Get our mini-batch.\n",
    "            Z_batch = iter_train.next()\n",
    "            X_batch, y_batch = ch.dataset.concat_examples(Z_batch)\n",
    "\n",
    "            # Get the un-normalized log-probability outputs.\n",
    "            prediction_tr = mod_chainer(X_batch)\n",
    "            \n",
    "            #np.concatenate((mod_chainer(X_batch).data,\n",
    "            #                                np.zeros((X_batch.shape[0],1), dtype=np.float32)),\n",
    "            #                               axis=1) # need to append zeros for 1-probs.\n",
    "\n",
    "            # Loss computations (will feed the grad computations).\n",
    "            loss = ch.functions.softmax_cross_entropy(x=prediction_tr,\n",
    "                                                      t=np.int8(data.y_tr).flatten(),\n",
    "                                                      normalize=True,\n",
    "                                                      reduce=\"mean\")\n",
    "            \n",
    "            # Gradient computations.\n",
    "            mod_chainer.cleargrads()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Parameter updates.\n",
    "            opt_chainer.update()\n",
    "            \n",
    "            # Record performance.\n",
    "            loss_tr[tri,idx,mthidx] = loss.data-loss_star\n",
    "            prediction_te = mod_chainer(data.X_te)\n",
    "            accuracy = ch.functions.accuracy(y=prediction_te,\n",
    "                                             t=np.int8(data.y_te).flatten()).data\n",
    "            \n",
    "            riskvals[tri,idx,mthidx] = 1.0-accuracy-risk_star\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "# Finally, take statistics of the performance metrics over all trials.\n",
    "ave_loss_tr = np.mean(loss_tr, axis=0)\n",
    "ave_riskvals = np.mean(riskvals, axis=0)\n",
    "sd_loss_tr = np.std(loss_tr, axis=0)\n",
    "sd_riskvals = np.std(riskvals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一つ注目すべきは、`Chain_LinReg`をそのまま使っていることである。前の節の文脈では、このモデルを線形回帰のために整備したのだが、ロジスティック回帰に必要な演算はすべてカバーされているので、問題なく使える。回帰モデルとの違いがどこにあるかというと、今回は実数スカラーではなく、多次元ベクトルを出していることと、その出力がsoftmax cross-entropyに渡されていることである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualization of performance.\n",
    "\n",
    "tvals = np.arange(t_max)+1 # better to start from the first update.\n",
    "\n",
    "# Average over trials.\n",
    "myfig = plt.figure(figsize=(15,5))\n",
    "\n",
    "ax_loss_tr = myfig.add_subplot(1, 3, 1)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_loss_tr[:,m]\n",
    "    err = sd_loss_tr[:,m]\n",
    "    ax_loss_tr.plot(tvals, vals, color=mth_colours[m], label=mth_names[m])\n",
    "    ax_loss_tr.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Primal loss (training)\")\n",
    "\n",
    "ax_riskvals = myfig.add_subplot(1, 3, 2)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_riskvals[:,m]\n",
    "    err = sd_riskvals[:,m]\n",
    "    err_log = err / vals\n",
    "    ax_riskvals.plot(tvals, vals, \"-\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_riskvals.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Misclassification rate (test)\")\n",
    "\n",
    "ax_variation = myfig.add_subplot(1, 3, 3)\n",
    "for m in m_idx_todo:\n",
    "    vals = sd_riskvals[:,m]\n",
    "    ax_variation.plot(tvals, vals, \"-\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_variation.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Variation of error across trials\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file connection.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__練習問題__\n",
    "\n",
    "0. 基本的な振る舞いが似ているとはいえ、`lgstReg`と`lgstReg-ch`がまったく同じ働きをしているわけではない。これはなぜだろうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chainer_newopt\"></a>\n",
    "### 最適化を自分の手で\n",
    "\n",
    "これまでのChainerを用いた事例では、標準整備された`Optimizer`サブクラスを使っている。具体的には、`SGD`というサブクラスで、確率的勾配降下法を実装したものであるが、これまでの例ではミニバッチの大きさを$n$としているので、結局は決定論的な勾配降下法(GD)であった。\n",
    "\n",
    "最適化法を自分で調整・改造したいときには、主として糸口が2つある。（１）`Optimizer`サブクラスを自分で作って、上と同様に使うこと。（２）そもそも`Optimizer`の枠組みを使わずに、モデルが管理する`Parameter`オブジェクト自体を操作すること。\n",
    "\n",
    "前者ではCPU/GPUハードウェアを駆使することがきわめて楽であるが、自由度が比較的低く、実装できるアルゴリズムが限られてしまう。後者では、考えられる範囲でほとんど何でもできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自力でGDを行う簡単な例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment setup.\n",
    "\n",
    "# Data-related.\n",
    "data = dataclass.DataSet() # Initialize one data object; will be re-populated at each trial.\n",
    "n = 500 # sample size\n",
    "d = 2 # number of parameters\n",
    "init_delta = 5.0 # controls support of random initialization\n",
    "num_trials = 250 # number of independent random trials to conduct\n",
    "cov_X = np.eye(d) # covariance matrix of the inputs.\n",
    "\n",
    "w_star = np.ones(d).reshape((d,1)) # vector specifying true model\n",
    "\n",
    "# Algorithm-related.\n",
    "m_idx_todo = [0,1] # let's us manually pick and choose which methods to evaluate.\n",
    "t_max = 30 # termination condition; maximum number of iterations.\n",
    "thres = -1.0 # termination condition; if negative, runs for max iterations.\n",
    "\n",
    "def alpha_fixed(t, val): # step-size callback function.\n",
    "    return val\n",
    "def make_step(u):\n",
    "    def mystep(t, model=None, data=None, newdir=None):\n",
    "        return alpha_fixed(t=t, val=u)\n",
    "    return mystep\n",
    "alphaval = 0.25\n",
    "\n",
    "# Clerical.\n",
    "mth_names = [\"gd\", \"gd-ch\"]\n",
    "num_mths = len(mth_names)\n",
    "mth_colours = [\"black\", \"blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make choice of additive noise distribution (un-comment your choice).\n",
    "#paras = {\"name\": \"norm\", \"shift\": 0.0, \"scale\": 20.0}\n",
    "paras = {\"name\": \"lnorm\", \"meanlog\": 0.0, \"sdlog\": 1.75}\n",
    "\n",
    "# Put together risk function.\n",
    "def risk(w):\n",
    "    mean_noise, var_noise = hlp.noise_risk(paras=paras)\n",
    "    return hlp.riskMaker(w=w, A=cov_X, b=math.sqrt(var_noise), w_star=w_star)\n",
    "risk_star = risk(w=w_star) # optimal risk value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the algorithms.\n",
    "\n",
    "# Prepare storage for performance metrics.\n",
    "riskvals = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "loss_tr = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "truedist = np.zeros((num_trials,t_max,num_mths), dtype=np.float32)\n",
    "\n",
    "# Loop over trials.\n",
    "for tri in range(num_trials):\n",
    "    \n",
    "    # Generate new data (with *centered* noise).\n",
    "    X = np.random.normal(loc=0.0, scale=1.0, size=(n,d))\n",
    "    noise = hlp.noise_data(n=n, paras=paras)\n",
    "    y = np.dot(X, w_star) + noise\n",
    "    data.init_tr(X=X, y=y)\n",
    "    \n",
    "    # Data for Chainer model.\n",
    "    Z = ch.datasets.TupleDataset(np.float32(X),\n",
    "                                 np.float32(y))\n",
    "    \n",
    "    # Initial weight settings.\n",
    "    w_init = w_star + np.random.uniform(low=-init_delta, high=init_delta, size=d).reshape((d,1))\n",
    "    w_init = np.float32(w_init)\n",
    "    \n",
    "    # Initialize models (hand-built).\n",
    "    mod_learner = models.LinearL2(data=data)\n",
    "    risk_star = risk(w=w_star) # optimal risk value.\n",
    "    loss_star = np.mean(mod_learner.l_tr(w=w_star, data=data))\n",
    "    \n",
    "    # Initialize models (Chainer-based).\n",
    "    mod_chainer = Chain_LinReg(out_l0=d,\n",
    "                          out_l1=1,\n",
    "                          init_W=w_init.T,\n",
    "                          init_b=None,\n",
    "                          init_delta=init_delta,\n",
    "                          nobias=True)\n",
    "    \n",
    "    # Initialize algorithms (hand-built).\n",
    "    al_gd = algorithms.Algo_GD(w_init=w_init,\n",
    "                               step=make_step(alphaval),\n",
    "                               t_max=t_max,\n",
    "                               thres=thres,\n",
    "                               store=True,\n",
    "                               lamreg=None)\n",
    "\n",
    "    \n",
    "    # Run all algorithms and save their performance.\n",
    "    \n",
    "    ## ERM-GD.\n",
    "    mthidx = 0\n",
    "    if mthidx in m_idx_todo:        \n",
    "        idx = 0\n",
    "        for mystep in al_gd:\n",
    "            al_gd.update(model=mod_learner, data=data)\n",
    "            # Record performance\n",
    "            loss_tr[tri,idx,mthidx] = np.mean(mod_learner.l_tr(w=al_gd.w, data=data))-loss_star\n",
    "            riskvals[tri,idx,mthidx] = risk(w=al_gd.w)-risk_star\n",
    "            truedist[tri,idx,mthidx] = np.linalg.norm(w_star-al_gd.w)-0\n",
    "            idx += 1\n",
    "        \n",
    "        \n",
    "    ## Replication of ERM using Chainer.\n",
    "    mthidx = 1\n",
    "    if mthidx in m_idx_todo:\n",
    "        idx = 0\n",
    "        iter_train = ch.iterators.SerialIterator(dataset=Z,\n",
    "                                                 batch_size=n, # thus SGD=GD; deterministic.\n",
    "                                                 repeat=True,\n",
    "                                                 shuffle=False)\n",
    "        while iter_train.epoch < t_max:\n",
    "\n",
    "            # Get our mini-batch.\n",
    "            Z_batch = iter_train.next()\n",
    "            X_batch, y_batch = ch.dataset.concat_examples(Z_batch)\n",
    "\n",
    "            # Predictions.\n",
    "            prediction_tr = mod_chainer(X_batch)\n",
    "\n",
    "            # Loss computations (will feed the grad computations).\n",
    "            loss = ch.functions.mean_squared_error(prediction_tr, y_batch) / 2.0\n",
    "            loss_star = np.mean(mod_learner.l_tr(w=w_star, data=data))\n",
    "            \n",
    "            # Gradient computations.\n",
    "            mod_chainer.cleargrads()\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter updates.\n",
    "            for p in mod_chainer.params():\n",
    "                grad = p.grad\n",
    "                if grad is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    p.data -= alphaval * grad\n",
    "            \n",
    "            # Record performance\n",
    "            loss_tr[tri,idx,mthidx] = np.mean(mod_learner.l_tr(w=mod_chainer.l1.W.data.T, data=data))-loss_star\n",
    "            riskvals[tri,idx,mthidx] = risk(w=mod_chainer.l1.W.data.T)-risk_star\n",
    "            truedist[tri,idx,mthidx] = np.linalg.norm(w_star-mod_chainer.l1.W.data.T)-0\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "# Finally, take statistics of the performance metrics over all trials.\n",
    "ave_loss_tr = np.mean(loss_tr, axis=0)\n",
    "ave_riskvals = np.mean(riskvals, axis=0)\n",
    "ave_truedist = np.mean(truedist, axis=0)\n",
    "sd_loss_tr = np.std(loss_tr, axis=0)\n",
    "sd_riskvals = np.std(riskvals, axis=0)\n",
    "sd_truedist = np.std(truedist, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualization of performance.\n",
    "\n",
    "tvals = np.arange(t_max)+1 # better to start from the first update.\n",
    "\n",
    "# Average over trials.\n",
    "myfig = plt.figure(figsize=(15,5))\n",
    "\n",
    "ax_loss_tr = myfig.add_subplot(1, 3, 1)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_loss_tr[:,m]\n",
    "    err = sd_loss_tr[:,m]\n",
    "    ax_loss_tr.plot(tvals, vals, color=mth_colours[m], label=mth_names[m])\n",
    "    #ax_loss_tr.errorbar(tvals, vals, yerr=err, fmt='-o', col=mth_colours[m], label=mth_names[m])\n",
    "    ax_loss_tr.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Excess empirical risk\")\n",
    "    \n",
    "\n",
    "ax_riskvals = myfig.add_subplot(1, 3, 2)\n",
    "for m in m_idx_todo:\n",
    "    vals = ave_riskvals[:,m]\n",
    "    err = sd_riskvals[:,m]\n",
    "    err_log = err / vals\n",
    "    ax_riskvals.semilogy(tvals, vals, \"-o\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_riskvals.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Excess risk\")\n",
    "\n",
    "ax_variation = myfig.add_subplot(1, 3, 3)\n",
    "for m in m_idx_todo:\n",
    "    vals = sd_riskvals[:,m]\n",
    "    ax_variation.plot(tvals, vals, \"-o\", color=mth_colours[m], label=mth_names[m])\n",
    "    ax_variation.legend(loc=1,ncol=1)\n",
    "    plt.axhline(y=0.0, color=\"black\")\n",
    "    plt.title(\"Variation of risk across samples\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__練習問題__\n",
    "\n",
    "0. 上のコードでは決定論的な勾配降下法を`Optimizer`枠組みの外で実装した。これを踏まえて、任意のミニバッチに対応できる確率的勾配降下法（SGD)に拡張すること。また、これが事前に指定する$T$回だけ反復するようにすること（注：`iter_train.epoch`の箇所は修正が必要）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
